{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-Linear Algebra and PyTorch Tensor Operations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharaniabhishek123/ML-Introduction/blob/main/01_Linear_Algebra_and_PyTorch_Tensor_Operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdwwASAjzpid"
      },
      "source": [
        "## Data Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QyL3gv0kbrF"
      },
      "source": [
        "The most important data structure in linear algebra which applies to Machine Learning is arguably the matrix, a 2-d array of numbers where each entry can be indexed via its row and column. \n",
        "\n",
        "\n",
        "We can think of an Excel spreadsheet, where you have offers from Company X and Company Y as two rows, and the columns represents some characteristic of each offer such as starting salary, bonus, or position.\n",
        "\n",
        "\n",
        "\n",
        "``` \n",
        "              Salary        Bonus            Position\n",
        "\n",
        "Google        150,000       23,000           Software Engineer\n",
        "\n",
        "Facebook      180,000       27,000           Data Scientist\n",
        "\n",
        "```\n",
        "The table format is especially suited to keep track of such data, where you can index by row and column to find, for example, Company Xâ€™s starting position. Matrices, similarly, are a multipurpose tool to hold all kinds of data, where the data we work in this book are of numerical form.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv7jl7CHlpDC"
      },
      "source": [
        "**A dataset, for example, has many individual data points with any number of associated features. These are called as Tensors in pytorch. They can run on GPU or TPU (a faster way to execute)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUsZ0L0Jlw4u"
      },
      "source": [
        "$X_{m,n} =\n",
        " \\begin{pmatrix}\n",
        "  x_{1,1} & x_{1,2} & \\cdots & x_{1,n} \\\\\n",
        "  X_{2,1} & x_{2,2} & \\cdots & x_{2,n} \\\\\n",
        "  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
        "  x_{m,1} & x_{m,2} & \\cdots & x_{m,n}\n",
        " \\end{pmatrix}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxG2RlV-mnRB"
      },
      "source": [
        "import torch "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7ChWTxI5At3"
      },
      "source": [
        "raw_data = [[1,2,3],[4,5,6],[7,8,9]]\n",
        "py_tensor_1 = torch.tensor(raw_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdrjfPOp4t_Y",
        "outputId": "b590f6cb-e8bc-469d-ef93-3717e04c35da"
      },
      "source": [
        "py_tensor_2 = torch.ones_like(py_tensor_1)\n",
        "print(\"Tensor with all Ones : \\n {}\".format(py_tensor_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor with all Ones : \n",
            " tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7Koc5GH5214",
        "outputId": "42df1835-3942-4ade-cdb8-db49381f415b"
      },
      "source": [
        "py_tensor_3 = torch.rand_like(py_tensor_1, dtype=torch.float)\n",
        "print(\"Tensor with random values : \\n {}\".format(py_tensor_3))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor with random values : \n",
            " tensor([[0.6069, 0.6491, 0.8380],\n",
            "        [0.8775, 0.3306, 0.2782],\n",
            "        [0.2359, 0.8762, 0.0229]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWmW6OXQA9NP",
        "outputId": "cd9d02aa-e2ed-400f-d201-87d4d21cfb6f"
      },
      "source": [
        "zeros = torch.zeros(2,3)\n",
        "print(zeros)\n",
        "\n",
        "ones = torch.ones(2,3)\n",
        "print(ones)\n",
        "\n",
        "torch.manual_seed(2508)\n",
        "random = torch.rand(2,3)\n",
        "\n",
        "print(random)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0.7136, 0.0417, 0.6294],\n",
            "        [0.8594, 0.3111, 0.8449]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnN9Z8GoBOBE",
        "outputId": "a3ff0a69-9541-4f6b-b63e-c11f9b83dc9a"
      },
      "source": [
        "torch.manual_seed(2508) # wrapper for initializing tensor , helps in identical computation on reproduction of same results.\n",
        "torch.rand(2,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7136, 0.0417, 0.6294],\n",
              "        [0.8594, 0.3111, 0.8449]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0AA-qr8BVWw",
        "outputId": "76d1597d-55dd-4629-e8bf-d57962d755ac"
      },
      "source": [
        "torch.rand(2,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4358, 0.3457, 0.0320],\n",
              "        [0.6301, 0.5709, 0.6966]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU189Y2UC-FF",
        "outputId": "b5e42ad1-0bfe-4b82-c738-e5e520e5816c"
      },
      "source": [
        "py_tensor = torch.rand((3,3), dtype=torch.float64) * 20 \n",
        "print(py_tensor)\n",
        "\n",
        "py_tensor_int = py_tensor.to(torch.int32)\n",
        "print(py_tensor_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[17.9249,  5.6975, 14.5636],\n",
            "        [ 0.7927, 19.0194,  4.2181],\n",
            "        [ 5.5401, 12.4066, 11.8336]], dtype=torch.float64)\n",
            "tensor([[17,  5, 14],\n",
            "        [ 0, 19,  4],\n",
            "        [ 5, 12, 11]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m9Qn0CX4ORt"
      },
      "source": [
        "## Creating a ndarray which is similar to tensor in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSocoM48xyFF",
        "outputId": "6afce75e-660c-43e5-97a9-f41d1feec321"
      },
      "source": [
        "import numpy as np \n",
        "n_arr = np.random.rand(3,3)\n",
        "n_arr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.88174719, 0.05232402, 0.73350235],\n",
              "       [0.60142393, 0.77982269, 0.131939  ],\n",
              "       [0.15174739, 0.10207621, 0.46569186]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fABMwNFo4eOU"
      },
      "source": [
        "## Creating a Tensor directly from ndarray . There are number of ways to create a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXVygH_cxyIC",
        "outputId": "ed5a9c3a-23a9-4e68-b9c9-8e891f10efe4"
      },
      "source": [
        "py_tensor = torch.tensor(n_arr)\n",
        "py_tensor\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8817, 0.0523, 0.7335],\n",
              "        [0.6014, 0.7798, 0.1319],\n",
              "        [0.1517, 0.1021, 0.4657]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41VRO-oi6xCP"
      },
      "source": [
        "## Properties of Tensor such as Shape, DataType and Device\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eanywJ6e6reP",
        "outputId": "4bc64943-38d7-48ef-ef82-b410f4e29a1b"
      },
      "source": [
        "print(f\"Shape of tensor: {py_tensor_3.shape}\")\n",
        "print(f\"Datatype of tensor: {py_tensor_3.dtype}\")\n",
        "print(f\"Device tensor is stored on: {py_tensor_3.device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 3])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTVEOWABme-P"
      },
      "source": [
        "**Matrix Operations**\n",
        "\n",
        "Matrices can be added, subtracted, and multiplied - there is no division of matrices, but there exists a similar concept called inversion. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyryHb4Ymu3E"
      },
      "source": [
        " $ \\begin{pmatrix}\n",
        "  2 & 3 & 4  \\\\\n",
        "  5 & 6 & 7  \\\\       \n",
        " \\end{pmatrix} \n",
        "       +\n",
        "\\begin{pmatrix}\n",
        "  5 & 6 & 7  \\\\\n",
        "  8 & 9 & 1  \\\\       \n",
        " \\end{pmatrix}  \n",
        " = \n",
        "\\begin{pmatrix}\n",
        "  7 & 9 & 11  \\\\\n",
        "  13 & 15 & 9  \\\\       \n",
        " \\end{pmatrix}  \\\\ $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gxUcf6kmu5s"
      },
      "source": [
        "$2 X \\begin{pmatrix}\n",
        "  2 & 3 & 4  \\\\\n",
        "  5 & 6 & 7  \\\\       \n",
        " \\end{pmatrix} = \n",
        " \\begin{pmatrix} 2*2 & 2*3 & 2*4  \\\\ 2*5 & 2*6 & 2*7  \\\\   \\end{pmatrix}\n",
        " = \\begin{pmatrix} 4 & 6 & 8  \\\\ 10 & 12 & 14  \\\\       \\end{pmatrix}  $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGuCIQZKmu8f"
      },
      "source": [
        "$ \\begin{pmatrix}\n",
        "  2 & 3   \\\\\n",
        "  4 & 5   \\\\  \\end{pmatrix} X \\begin{pmatrix}\n",
        "  5 & 6   \\\\\n",
        "  7 & 8   \\\\       \n",
        " \\end{pmatrix} = \\begin{pmatrix} 2*5 + 3*7 & 2*6 + 3*8 \\\\ 4*5 + 5*7 & 4*6 + 5 * 8 \\\\       \\end{pmatrix}= \\begin{pmatrix} 31 &  36  \\\\ 55  & 64  \\\\       \\end{pmatrix}  $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW-imc7cmu-q"
      },
      "source": [
        "Note : Two matrices are only multiplicable if the dimensions align, i.e. A is of dimension m by k and B is of dimension k by n. \n",
        "\n",
        "Other way of saying if the rows of A and the columns of B must have the same length, so two matrices can only be multiplied\n",
        "\n",
        "\n",
        "If this werenâ€™t the case, the formula for matrix multiplication would give us an indexing error. \n",
        "\n",
        "Weâ€™ll call the formula for matrix multiplication presented above the dot product interpretation of matrix multiplication, â€‹which will make more sense after reading the Vector Operations section.\n",
        "\n",
        "However, there are few exceptions to this rule and we will understand them deeper in Broadcasting Rules. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYof46lNsHMg"
      },
      "source": [
        "Matrix Multiplication are not commutative \\\\\n",
        "$ A . B !=  B.A  $ \\\\\n",
        "Matrix Multiplication are Associative \\\\\n",
        "$ A . (B + C) = A.B + B.C $ \\\\\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE4LHxVd6nKG"
      },
      "source": [
        "## Tensor Operations\n",
        "\n",
        "\n",
        "\n",
        "1.   Matrix Transpose\n",
        "2.   Multiplication\n",
        "3.   Move to GPU\n",
        "4.   In_place Operations\n",
        "5.   Joining\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjeXToiTbk-k"
      },
      "source": [
        "## Transpose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLcTxH27bnSS"
      },
      "source": [
        "tensor = torch.tensor([[2, 3, 4], [5, 6, 7]])\n",
        "tensor_T = tensor.T #.T transpose the tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdVwvqP_9tGe"
      },
      "source": [
        "## Scalar Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tz1Z96NxyMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b3eb0d-757b-43a9-e78c-43e3bb5aca69"
      },
      "source": [
        "c= 10\n",
        "new_tensor = torch.tensor([[2, 3, 4], [5, 6, 7]])\n",
        "new_tensor = tensor * c \n",
        "print(\"New Tensor after multiplication : \\n {}\".format(tensor))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Tensor after multiplication : \n",
            " tensor([[2, 3, 4],\n",
            "        [5, 6, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbiBwTz19w-F"
      },
      "source": [
        "## tensor multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZMLHoJ09q38",
        "outputId": "fb681b51-67ac-4bad-e709-b8ab30e9af49"
      },
      "source": [
        "a = torch.tensor([[2, 3], [4, 5]])\n",
        "\n",
        "b  = torch.tensor([[5, 6], [7, 8]])\n",
        "\n",
        "out1 = a @ b  \n",
        "out2 = a.matmul(b)\n",
        "\n",
        "\n",
        "print(\"result of multiplication a x b {}\".format(out1))\n",
        "out1 == out2 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result of multiplication a x b tensor([[31, 36],\n",
            "        [55, 64]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True],\n",
              "        [True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G3rIAv19o3u"
      },
      "source": [
        "## element-wise product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzpbzp5r9V-a",
        "outputId": "a3c58efe-6393-4f2b-c912-05052be64db5"
      },
      "source": [
        "out1 = a * b\n",
        "out2 = a.mul(b)\n",
        "\n",
        "print(\"result of elementwise multiplication a * b {}\".format(out1))\n",
        "\n",
        "out1 == out2 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result of elementwise multiplication a * b tensor([[10, 18],\n",
            "        [28, 40]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True],\n",
              "        [True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Prwy14x_z5"
      },
      "source": [
        "**Broadcasting Rules** \\\\\n",
        "\n",
        "Performing Operation only when there is some similarity in shape between tensors.\n",
        "The term broadcasting is how the tensor operation will take place incase, we are operating on tensors of different sizes. \n",
        "For example you are having an image input of 256x256x3 (3d input) and when we add one more dimension of row (to form mini-batches for SGD). \n",
        "\n",
        "input = torch.empty(10, 256, 256 ,3)\n",
        "bias = torch.empty(1,3) \n",
        "\n",
        "if we do addition or multiplication or substraction  \n",
        "\n",
        "it would be of shape (10, 256,256, 3)\n",
        "\n",
        "\n",
        "### Starting from last dimension and going towards first dimension . Two dimensions are broadcastable only when \n",
        "\n",
        "## Rule Condition 1 : they are equal \n",
        "## or \n",
        "## Rule Condition 2 : either of them is 1\n",
        "## or \n",
        "## Rule Condition 3 : either of them does not exist\n",
        "\n",
        "\n",
        "## Very Common Operation in ML where we multiply a tensor having weights(parameters) by batch of input (subset of input) for example a weight of shape (2,4) * (1, 4) returns a learned weight of (2,4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG_y5twID1FO",
        "outputId": "7976ef9e-9123-4411-e733-16913066478e"
      },
      "source": [
        "ones = torch.zeros(2,2) + 1 \n",
        "ones"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sn2VMMKxyOj"
      },
      "source": [
        "a = torch.ones(10, 256,256,3) # Compare dims last to first \n",
        "b = a * torch.rand(256,3) # 3rd and 2nd dim are indentical to a \n",
        "\n",
        "c = a * torch.rand(1,3) # 3rd dim is 3, 2nd dim is 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h46SCkWLyLuC"
      },
      "source": [
        "\n",
        "input_ = torch.empty(10, 256,256,3) # Compare dims last to first \n",
        "bias = torch.empty(1,1,3) \n",
        "\n",
        "\n",
        "y = input_ + bias \n",
        "z = input_ * bias # or y = torch.matmul(input_ , bias) \n",
        "u = input_ - bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycJ8abZdyO_8",
        "outputId": "a93a8940-54c9-4c82-d661-452a4daba5de"
      },
      "source": [
        "y.shape == z.shape == u.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLEyZazdySTD",
        "outputId": "4aa49918-6efd-4ada-aeb6-66eec9329a07"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 256, 256, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVcVt7ENyVeN"
      },
      "source": [
        "##Where as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAuxDsXGyUqY"
      },
      "source": [
        "input_ = torch.empty(10, 256,256,3)\n",
        "bias = torch.empty(1,2,3) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apy1LyKVcqWV"
      },
      "source": [
        "## Note : The error is intentional to show the size mismatch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "EoQd0rtezz-_",
        "outputId": "c634a218-b9c2-4097-8197-54e1eed76af9"
      },
      "source": [
        "y = input_ + bias \n",
        "z = input_ * bias # or y = torch.matmul(input_ , bias) \n",
        "u = input_ - bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-cf1af67e9229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;31m# or y = torch.matmul(input_ , bias)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (2) at non-singleton dimension 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAL1aHiLG_dF",
        "outputId": "99969ba3-d229-4b68-8913-3dfa50d915be"
      },
      "source": [
        "\n",
        "# bitwise operations\n",
        "print('\\nBitwise XOR:')\n",
        "b = torch.tensor([1, 5, 11])\n",
        "c = torch.tensor([2, 7, 10])\n",
        "print(torch.bitwise_xor(b, c))\n",
        "\n",
        "# comparisons:\n",
        "print('\\nBroadcasted, element-wise equality comparison:')\n",
        "d = torch.tensor([[1., 2.], [3., 4.]])\n",
        "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
        "print(torch.eq(d, e)) # returns a tensor of type bool\n",
        "\n",
        "# reductions:\n",
        "print('\\nReduction ops:')\n",
        "print(torch.max(d))        # returns a single-element tensor\n",
        "print(torch.max(d).item()) # extracts the value from the returned tensor\n",
        "print(torch.mean(d))       # average\n",
        "print(torch.std(d))        # standard deviation\n",
        "print(torch.prod(d))       # product of all numbers\n",
        "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bitwise XOR:\n",
            "tensor([3, 2, 1])\n",
            "\n",
            "Broadcasted, element-wise equality comparison:\n",
            "tensor([[ True, False],\n",
            "        [False, False]])\n",
            "\n",
            "Reduction ops:\n",
            "tensor(4.)\n",
            "4.0\n",
            "tensor(2.5000)\n",
            "tensor(1.2910)\n",
            "tensor(24.)\n",
            "tensor([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp33WTShyd9m"
      },
      "source": [
        "## Alter the Tensor Inplace \n",
        "Note : Any function call ending with _ suffix are in place changes to operand. No intermediate results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxiROXGPycga"
      },
      "source": [
        "tensor1 = torch.tensor([[1,2],[3,4]])\n",
        "tensor2 = torch.tensor([[1,2,3],[4,5,6]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIwGnKmLycjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3c20ad-909b-47ee-f1bc-328f1af08b25"
      },
      "source": [
        "print(tensor1)\n",
        "tensor1.add_(5)\n",
        "print(tensor1)\n",
        "tensor1.mul_(5)\n",
        "print(tensor1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[6, 7],\n",
            "        [8, 9]])\n",
            "tensor([[30, 35],\n",
            "        [40, 45]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3oHAP-BJQUk"
      },
      "source": [
        "## Copying a Tensor\n",
        "\n",
        "Two or more paths in the model using same layer weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOQGwms6JOpI",
        "outputId": "186c698b-b23d-46f0-d597-7fca77b83c2f"
      },
      "source": [
        "a = torch.ones(3,3)\n",
        "b = a.clone() # by default copies the autgrade value from source tensor \n",
        "\n",
        "c = a.detach().clone() # does not store  store computation history for c \n",
        "\n",
        "id(a) == id(b)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Oif9tzlKcKi"
      },
      "source": [
        "## Moving to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2M4cC5WIqtU",
        "outputId": "43559c4d-2410-403a-a2b8-ef0f5d2f2513"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('We have a GPU!')\n",
        "else:\n",
        "    print('Sorry, CPU only.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, CPU only.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMKrFnFRKxUh"
      },
      "source": [
        "## Manipulating Tensor Shapes\n",
        "\n",
        "Sometimes, you'll need to change the shape of your tensor. Below, we'll look at a few common cases, and how to handle them.\n",
        "\n",
        "### Changing the Number of Dimensions\n",
        "\n",
        "One case where you might need to change the number of dimensions is passing a single instance of input to your model. PyTorch models generally expect *batches* of input.\n",
        "\n",
        "For example, imagine having a model that works on 3 x 226 x 226 images - a 226-pixel square with 3 color channels. When you load and transform it, you'll get a tensor of shape `(3, 226, 226)`. Your model, though, is expecting input of shape `(N, 3, 226, 226)`, where `N` is the number of images in the batch. So how do you make a batch of one?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nukd9JjcKwn4",
        "outputId": "473fcd8e-467e-45e9-a912-479edba8f59b"
      },
      "source": [
        "a = torch.rand(3, 226, 226)\n",
        "b = a.unsqueeze(0)\n",
        "\n",
        "print(a.shape)\n",
        "print(b.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 226, 226])\n",
            "torch.Size([1, 3, 226, 226])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqDN7OlHK1kh"
      },
      "source": [
        "The `unsqueeze()` method adds a dimension of extent 1. `unsqueeze(0)` adds it as a new zeroth dimension - now you have a batch of one!\n",
        "\n",
        "So if that's *un*squeezing? What do we mean by squeezing? We're taking advantage of the fact that any dimension of extent 1 *does not* change the number of elements in the tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvqJtvBTb6WM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvZqRMR-b6Zb"
      },
      "source": [
        "Continuing the example above, let's say the model's output is a 20-element vector for each input. You would then expect the output to have shape `(N, 20)`, where `N` is the number of instances in the input batch. That means that for our single-input batch, we'll get an output of shape `(1, 20)`.\n",
        "\n",
        "What if you want to do some *non-batched* computation with that output - something that's just expecting a 20-element vector?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMxUit0Ub84D",
        "outputId": "e4c42a75-1cda-4fa0-a1a2-ef2400fbf64f"
      },
      "source": [
        "a = torch.rand(1, 20)\n",
        "print(a.shape)\n",
        "print(a)\n",
        "\n",
        "b = a.squeeze(0)\n",
        "print(b.shape)\n",
        "print(b)\n",
        "\n",
        "c = torch.rand(2, 2)\n",
        "print(c.shape)\n",
        "\n",
        "d = c.squeeze(0)\n",
        "print(d.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 20])\n",
            "tensor([[0.3892, 0.2961, 0.3125, 0.0115, 0.0909, 0.2101, 0.5266, 0.4698, 0.0137,\n",
            "         0.4796, 0.6653, 0.5503, 0.0496, 0.8904, 0.1333, 0.6137, 0.6695, 0.8352,\n",
            "         0.4915, 0.3754]])\n",
            "torch.Size([20])\n",
            "tensor([0.3892, 0.2961, 0.3125, 0.0115, 0.0909, 0.2101, 0.5266, 0.4698, 0.0137,\n",
            "        0.4796, 0.6653, 0.5503, 0.0496, 0.8904, 0.1333, 0.6137, 0.6695, 0.8352,\n",
            "        0.4915, 0.3754])\n",
            "torch.Size([2, 2])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diKHQ5KQb7zt"
      },
      "source": [
        "You can see from the shapes that our 2-dimensional tensor is now 1-dimensional, and if you look closely at the output of the cell above you'll see that printing `a` shows an \"extra\" set of square brackets `[]` due to having an extra dimension.\n",
        "\n",
        "You may only `squeeze()` dimensions of extent 1. See above where we try to squeeze a dimension of size 2 in `c`, and get back the same shape we started with. Calls to `squeeze()` and `unsqueeze()` can only act on dimensions of extent 1 because to do otherwise would change the number of elements in the tensor.\n",
        "\n",
        "Another place you might use `unsqueeze()` is to ease broadcasting. Recall the example above where we had the following code:\n",
        "\n",
        "```\n",
        "a =     torch.ones(4, 3, 2)\n",
        "\n",
        "c = a * torch.rand(   3, 1) # 3rd dim = 1, 2nd dim identical to a\n",
        "print(c)\n",
        "```\n",
        "\n",
        "The net effect of that was to broadcast the operation over dimensions 0 and 2, causing the random, 3 x 1 tensor to be multiplied element-wise by every 3-element column in `a`.\n",
        "\n",
        "What if the random vector had just been  3-element vector? We'd lose the ability to do the broadcast, because the final dimensions would not match up according to the broadcasting rules. `unsqueeze()` comes to the rescue:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-nEypmPcHVK",
        "outputId": "70ead887-5264-48bc-984d-6feffa674af5"
      },
      "source": [
        "a = torch.ones(4, 3, 2)\n",
        "b = torch.rand(   3)     # trying to multiply a * b will give a runtime error\n",
        "c = b.unsqueeze(1)       # change to a 2-dimensional tensor, adding new dim at the end\n",
        "print(b.shape)\n",
        "print(c.shape)\n",
        "print(a * c)             # broadcasting works again!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3])\n",
            "torch.Size([3, 1])\n",
            "tensor([[[0.0765, 0.0765],\n",
            "         [0.2740, 0.2740],\n",
            "         [0.5332, 0.5332]],\n",
            "\n",
            "        [[0.0765, 0.0765],\n",
            "         [0.2740, 0.2740],\n",
            "         [0.5332, 0.5332]],\n",
            "\n",
            "        [[0.0765, 0.0765],\n",
            "         [0.2740, 0.2740],\n",
            "         [0.5332, 0.5332]],\n",
            "\n",
            "        [[0.0765, 0.0765],\n",
            "         [0.2740, 0.2740],\n",
            "         [0.5332, 0.5332]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRXJEzdXcLoR",
        "outputId": "3bd03f7e-5e6d-4d2d-d4da-03c79ce32a9c"
      },
      "source": [
        "batch_me = torch.rand(3, 226, 226)\n",
        "print(batch_me.shape)\n",
        "batch_me.unsqueeze_(0)\n",
        "print(batch_me.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 226, 226])\n",
            "torch.Size([1, 3, 226, 226])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0l7t9EeKwqt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdATTLc3yrII"
      },
      "source": [
        "## Gradients in Pytorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y47f3u2fyzgw"
      },
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = torch.tensor(3.0, requires_grad=True)\n",
        "z = torch.tensor(1.5, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRJVTgtSyqFO"
      },
      "source": [
        "f = x**2 + y**2 + z**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7p2cL17yqH1"
      },
      "source": [
        "f.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wXB3MDpy3Av",
        "outputId": "bd285ab0-d789-49dd-c25a-9c5befa934c8"
      },
      "source": [
        "x.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqmLUoAYy3DW",
        "outputId": "9046c4c9-38ce-483e-8c4c-31aa68d59fc9"
      },
      "source": [
        "y.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONYGmpbny3GY",
        "outputId": "a16eadd6-ca10-47d6-fb3a-ef41c4cb5508"
      },
      "source": [
        "z.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIvgBPtxy8Yx"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqI0Rr6Zy_G2"
      },
      "source": [
        "in_dim, out_dim = 256, 10 \n",
        "vec = torch.randn(256)\n",
        "layer = nn.Linear(in_dim, out_dim, bias=True)\n",
        "out = layer(vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkc2S-PozA_4"
      },
      "source": [
        "# out = torch.matmul(W, vec) + b "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9m8qeXOzCq8"
      },
      "source": [
        "class BaseClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, feature_dim, out_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Linear(in_dim, feature_dim, bias=True)\n",
        "        \n",
        "        self.layer2 = nn.Linear(feature_dim, out_dim, bias=True)\n",
        "        self.relu = nn.Relu()\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        int_out = self.layer1(inp)\n",
        "        int_out = self.relu(int_out)\n",
        "        out = self.layer2(int_out)\n",
        "        return out \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjDSO9n-z3FD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}