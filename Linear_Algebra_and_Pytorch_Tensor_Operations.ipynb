{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Algebra and Pytorch Tensor Operations.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN9+DBycJGww3a7NrjNDoGI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharaniabhishek123/ML-Introduction/blob/main/Linear_Algebra_and_Pytorch_Tensor_Operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee3DGgvAkADf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QyL3gv0kbrF"
      },
      "source": [
        "The most important data structure in linear algebra which applies to Machine Learning is arguably the matrix, a 2-d array of numbers where each entry can be indexed via its row and column. \n",
        "\n",
        "\n",
        "We can think of an Excel spreadsheet, where you have offers from Company X and Company Y as two rows, and the columns represents some characteristic of each offer such as starting salary, bonus, or position.\n",
        "\n",
        "\n",
        "\n",
        "``` \n",
        "              Salary        Bonus            Position\n",
        "\n",
        "Google        150,000       23,000           Software Engineer\n",
        "\n",
        "Facebook      180,000       27,000           Data Scientist\n",
        "\n",
        "```\n",
        "The table format is especially suited to keep track of such data, where you can index by row and column to find, for example, Company X’s starting position. Matrices, similarly, are a multipurpose tool to hold all kinds of data, where the data we work in this book are of numerical form.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv7jl7CHlpDC"
      },
      "source": [
        "**In deep learning, matrices are often used to represent both datasets and weights in a neural network. A dataset, for example, has many individual data points with any number of associated features.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUsZ0L0Jlw4u"
      },
      "source": [
        "$X_{m,n} =\n",
        " \\begin{pmatrix}\n",
        "  x_{1,1} & x_{1,2} & \\cdots & x_{1,n} \\\\\n",
        "  X_{2,1} & x_{2,2} & \\cdots & x_{2,n} \\\\\n",
        "  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
        "  x_{m,1} & x_{m,2} & \\cdots & x_{m,n}\n",
        " \\end{pmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTVEOWABme-P"
      },
      "source": [
        "**Matrix Operations**\n",
        "\n",
        "Matrices can be added, subtracted, and multiplied - there is no division of matrices, but there exists a similar concept called inversion. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyryHb4Ymu3E"
      },
      "source": [
        " $ \\begin{pmatrix}\n",
        "  2 & 3 & 4  \\\\\n",
        "  5 & 6 & 7  \\\\       \n",
        " \\end{pmatrix} \n",
        "       +\n",
        "\\begin{pmatrix}\n",
        "  5 & 6 & 7  \\\\\n",
        "  8 & 9 & 1  \\\\       \n",
        " \\end{pmatrix}  \n",
        " = \n",
        "\\begin{pmatrix}\n",
        "  7 & 9 & 11  \\\\\n",
        "  13 & 15 & 9  \\\\       \n",
        " \\end{pmatrix}  \\\\ $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gxUcf6kmu5s"
      },
      "source": [
        "$2 * \\begin{pmatrix}\n",
        "  2 & 3 & 4  \\\\\n",
        "  5 & 6 & 7  \\\\       \n",
        " \\end{pmatrix} = \n",
        " \\begin{pmatrix} 2*2 & 2*3 & 2*4  \\\\ 2*5 & 2*6 & 2*7  \\\\   \\end{pmatrix}\n",
        " = \\begin{pmatrix} 4 & 6 & 8  \\\\ 10 & 12 & 14  \\\\       \\end{pmatrix}  $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGuCIQZKmu8f"
      },
      "source": [
        "$ \\begin{pmatrix}\n",
        "  2 & 3   \\\\\n",
        "  4 & 5   \\\\  \\end{pmatrix} * \\begin{pmatrix}\n",
        "  5 & 6   \\\\\n",
        "  7 & 8   \\\\       \n",
        " \\end{pmatrix} = \\begin{pmatrix} 2*5 + 3*7 & 2*6 + 3*8 \\\\ 4*5 + 5*7 & 4*6 + 5 * 8 \\\\       \\end{pmatrix}= \\begin{pmatrix} 31 &  30  \\\\ 55  & 64  \\\\       \\end{pmatrix}  $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW-imc7cmu-q"
      },
      "source": [
        "Note : Two matrices are only multiplicable if the dimensions align, i.e. A is of dimension m by k and B is of dimension k by n. \n",
        "\n",
        "Other way of saying if the rows of A and the columns of B must have the same length, so two matrices can only be multiplied\n",
        "\n",
        "\n",
        "If this weren’t the case, the formula for matrix multiplication would give us an indexing error. \n",
        "\n",
        "We’ll call the formula for matrix multiplication presented above the dot product interpretation of matrix multiplication, ​which will make more sense after reading the Vector Operations section.\n",
        "\n",
        "However, there are few exceptions to this rule and we will understand them deeper in Broadcasting Rules. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYof46lNsHMg"
      },
      "source": [
        "Matrix Multiplication are not commutative \\\\\n",
        "$ A . B !=  B.A  $ \\\\\n",
        "Matrix Multiplication are Associative \\\\\n",
        "$ A . (B + C) = A.B + B.C $ \\\\\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxG2RlV-mnRB"
      },
      "source": [
        "import numpy as np \n",
        "import torch "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSocoM48xyFF"
      },
      "source": [
        "n_arr = np.random.rand(3,3)\n",
        "n_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXVygH_cxyIC"
      },
      "source": [
        "py_tensor = torch.tensor(n_arr)\n",
        "py_tensor\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tz1Z96NxyMF"
      },
      "source": [
        "c= 10\n",
        "new_py_tensor = py_tensor * c "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Prwy14x_z5"
      },
      "source": [
        "**Broadcasting Rules** \\\\\n",
        "The term broadcasting is how the tensor operation will take place incase, we are operating on tensors of different sizes. \n",
        "For example you are having an image input of 256x256x3 (3d input) and when we add one more dimension of row (to form mini-batches for SGD). \n",
        "\n",
        "input = torch.empty(8, 1, ,6 ,1)\n",
        "bias = torch.empty(7,1,5) \n",
        "\n",
        "if we do addition or multiplication or substraction  \n",
        "\n",
        "it would be of shape (8, 7, 6, 5)\n",
        "\n",
        "\n",
        "### Starting from last dimension and going towards first dimension . Two dimensions are broadcastable only when \n",
        "\n",
        "## Rule Condition 1 : they are equal \n",
        "## or \n",
        "## Rule Condition 2 : either of them is 1\n",
        "## or \n",
        "## Rule Condition 3 : either of them does not exist\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "7sn2VMMKxyOj",
        "outputId": "8cbf42b7-b046-419d-ce32-044dbe2badae"
      },
      "source": [
        "input_ = torch.empty(8, 1,6 ,1)\n",
        "bias = torch.empty(7,1,5) "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d87d806707c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "h46SCkWLyLuC",
        "outputId": "29a850e0-0b41-4058-f775-fc9f702bcb79"
      },
      "source": [
        "y = input_ + bias \n",
        "z = input_ * bias # or y = torch.matmul(input_ , bias) \n",
        "u = input_ - bias"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cf1af67e9229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;31m# or y = torch.matmul(input_ , bias)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycJ8abZdyO_8"
      },
      "source": [
        "y.shape == z.shape == u.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "GLEyZazdySTD",
        "outputId": "378a7f92-0a63-432c-d093-6488283e6db4"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3d861059fa55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVcVt7ENyVeN"
      },
      "source": [
        "##Where as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAuxDsXGyUqY"
      },
      "source": [
        "input_ = torch.empty(8, 7,6 ,4)\n",
        "bias = torch.empty(7,6,5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp33WTShyd9m"
      },
      "source": [
        "## Tensor Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxiROXGPycga"
      },
      "source": [
        "tensor1 = torch.tensor([[1,2],[3,4]])\n",
        "tensor2 = torch.tensor([[1,2,3],[4,5,6]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIwGnKmLycjC"
      },
      "source": [
        "tensor3 = torch.matmul(tensor1,tensor2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdATTLc3yrII"
      },
      "source": [
        "## Gradients in Pytorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y47f3u2fyzgw"
      },
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = torch.tensor(3.0, requires_grad=True)\n",
        "z = torch.tensor(1.5, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRJVTgtSyqFO"
      },
      "source": [
        "f = x**2 + y**2 + z**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7p2cL17yqH1"
      },
      "source": [
        "f.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wXB3MDpy3Av"
      },
      "source": [
        "x.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqmLUoAYy3DW"
      },
      "source": [
        "y.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONYGmpbny3GY"
      },
      "source": [
        "z.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIvgBPtxy8Yx"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqI0Rr6Zy_G2"
      },
      "source": [
        "in_dim, out_dim = 256, 10 \n",
        "vec = torch.randn(256)\n",
        "layer = nn.Linear(in_dim, out_dim, bias=True)\n",
        "out = layer(vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkc2S-PozA_4"
      },
      "source": [
        "# out = torch.matmul(W, vec) + b "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9m8qeXOzCq8"
      },
      "source": [
        "class BaseClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, feature_dim, out_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Linear(in_dim, feature_dim, bias=True)\n",
        "        \n",
        "        self.layer2 = nn.Linear(feature_dim, out_dim, bias=True)\n",
        "        self.relu = nn.Relu()\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        int_out = self.layer1(inp)\n",
        "        int_out = self.relu(int_out)\n",
        "        out = self.layer2(int_out)\n",
        "        return out \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}